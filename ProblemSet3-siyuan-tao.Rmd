---
title: Forecasting the 2020 American Federal Election Using Multilevel Regression
  with Post-stratification
author: "Siyuan Tao"
date: "2020-11-01"
output:
  pdf_document:
    latex_engine: xelatex
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
library(tidyverse)
setwd("~/Desktop/STA304 P3")
# Loading in the cleaned survey Data
survey_data <- read_csv("output/survey_data.csv")

# Loading in the cleaned census Data
census_data <- read_csv("output/census_data.csv")

```

# Forecasting the 2020 American Federal Election Using Multilevel Regression with Post-stratification

## Siyuan Tao
## 2020-11-01


# Model

The 2020 American federal election is in progress (Macaya, Hayes & Wagner, 2020). During the election, two major candidates are Donald Trump and Joe Biden (Macaya, Hayes & Wagner, 2020). In this report, we want to predict the election's vote outcome using multilevel regression with post-stratification. This part involves three sub-sections. In the first section, we build the multilevel regression model using survey data from Tausanovitch, Chris, and Lynn Vavreck (2020). In the second section, we make the post-stratification calculation using the regression model and the census data from IPUMS (Ruggles et al., 2020). In the last section, we will discuss some pre-cleanings we did for the two datasets we used.

## Model Specifics

In this report, we will be using a logistic regression model to predict the proportion of voters who will vote for Donald Trump. Whether voting for Donald Trump is a binary response variable, which means the variable only has two outcomes. More specifically: 

\begin{equation}
Y = 
\begin{cases} 
1 & \text{if voting for Donald Trump} \\
0        & \text{Otherwise}
\end{cases}
\end{equation}

In this case, using a linear regression model to predict the variable is not appropriate, as the levels of the variable do not form a straight line. Thus, we choose to use the logistic regression model to predict whether a voter will vote for Donald Trump.  

Previous studies have indicated that people's age, gender, race, and socioeconomic status can influence their political attitudes, resulting in different voting decisions (Pratto, Stallworth & Sidanius, 1997; Lockerbie, 2013; Harmel & Yeh, 2015; Patterson & Caldeira, 1983). Early data also shows that people from different states may prefer diverse candidates (Federal Election Commission, 2017). Thus, in this model, we will use five variables to predict whether people will vote for Donald Trump. These five variables include age, gender, race-ethnicity, household income, and states where people live. We are going to use R (R Core Team, 2019) to build the model. After applying these variables, our model is:

\begin{align}
log(\frac{\hat{p}}{1-\hat{p}}) =  \beta_{0} + \beta_{1}x_{age} + \beta_{2}x_{gender} + \beta_{3}x_{race_ethnicity} + \beta_{4}x_{household_income} + \beta_{5}x_{state}
\end{align}

The model suggests that whether a person will vote for Donald Trump depends on their age, gender, race, household income, and states they live. Here, $\hat{p}$ represents the probability of voting for Donald Trump. It can also represent the proportion of people who are from a specific demographic group and vote for Donald Trump. Besides, $\beta_0$ is the intercept of the model, which means that if all other variables are 0, $log(\frac{\hat{p}}{1-\hat{p}})$ will be expected to be $\beta_0$, so the probability of voting for Donald Trump is expected to be $\frac{e^{\beta_0}}{e^{\beta_0} + 1}$. In addition, $\beta_1$,$\beta_2$, $\beta_3$, $\beta_4$, and $\beta_5$ are coefficients that represent how $log(\frac{\hat{p}}{1-\hat{p}})$ changes based on the corresponding $x$. For example, $\beta_1$ indicates that when age increases by one unit, $log(\frac{\hat{p}}{1-\hat{p}})$ will be expected to increase by $\beta_1$, if holding all other variables as constant. 

```{r, include=FALSE}

# Creating the Model
model <- glm(vote_trump ~ age + gender + race_ethnicity + household_income + state, 
            data = survey_data, family = "binomial")

# Model Results (to Report in Results section)

model_summary <- broom::tidy(model)

```

## Post-Stratification 

We want to do a post-stratification analysis and apply our logistic regression model to the extensive census data to estimate the proportion of people who will vote for Donald Trump based on their different demographic features. Post-stratification is a useful method to estimate the target population using data from a non-representative sample (Wang et al., 2014). The basic process of post-stratification is to divide the population into small cells based on demographic features, then calculate the estimated variable in each cell, and finally weigh each cell and aggregate these cell estimates to get an accurate population-level estimate (Wang et al., 2014). 

Here, we divide people into different cells based on different ages, genders, races, household income levels, and states. These variables influence people's political decisions and can be found in both survey data and census data. One example of a cell could be the 30-year-old White males who live in New York and earn between \$100,000 to \$149,999. After getting the estimated proportion for each cell, $\hat{y}_{i}$, we want to use these estimates to infer how the entire population will vote and get the probability that Donald Trump will win the election. First, we multiply the estimated proportion of each cell by the cell's population size, ${N}_{j}\hat{y}_{i}$. Then, we can get the post-stratification estimate for the entire population, $\hat{y}^{PS}$ , by summing these products of all cells and dividing it by the total population size:

\begin{equation}
\hat{y}^{PS} = \frac{\sum{N}_{j}\hat{y}_{i}}{\sum{N}_{j}}
\end{equation}

However, one thing we need to remember is that our model is a logistic regression model, so  $\hat{y}^{PS}$ is an estimate of $log(\frac{\hat{p}}{1-\hat{p}})$, where $\hat{p}$ is the estimate of the proportion of people who will vote for Donald Trump. So we need to calculate $\hat{p}$ after getting $\hat{y}^{PS}$, which is:

\begin{equation}
\hat{p} = \frac{e^{\hat{y}^{PS}}}{1+ e^{\hat{y}^{PS}}}
\end{equation}


```{r, include=FALSE}

# Here I will perform the post-stratification calculation
census_data$estimate <-
  model %>%
  predict(newdata = census_data)

census_data %>%
  mutate(alp_predict_prop = estimate*n) %>%
  summarise(alp_predict = sum(alp_predict_prop)/sum(n))


```

## Data Preparation

First, we are going to talk about some preparation we did for the survey data. There were initially five different responses when people were asked who they would vote, which are "Donald Trump," "Joe Biden," "I am not sure/don't know," "I am not sure/don't know," and "Someone else." Because the two major candidates for the 2020 election are "Donald Trump" and "Joe Biden," we focused on participants who chose one of these two answers and removed data of the other three responses. Besides, we simplified some variables by grouping them into categories. For example, instead of having 24 different levels for the variable "Household Income," we simplified it into five categories. Similarly, we simplified the variable "Race Ethnicity" into five different categories. We also changed the states in the survey data to a full-name form to make the data match the census data using functions created by Christopher E. O'Brien (2012).

We also made some similar changes to the census data. For example, we changed the variable "Household Income" to the same five levels as the survey data. Besides, we renamed some census data variables to make the two datasets match with each other. Another thing we want to mention is that there are two specific levels under the variable "Age," which are "less than 1 year old" and "90 (90+ in 1980 and 1990)." To simplify the analysis, we assume that the age of the people who are "less than 1 year old" is 1, and the age of people who are "90 (90+ in 1980 and 1990)" is 90.

# Results

```{r, echo=FALSE}
head(model_summary)
```

This is the brief summary of the logistic regression model. The full table of the model that contains all coefficents will be posted in the Appendix. After applying the model to the census data, we calculate $\hat{y}^{PS}$, which is $-0.1032828$. The number means that based on our model, we expect  $log(\frac{\hat{p}}{1-\hat{p}})$ to be $-0.1032828$. By applying equation (4), we can calculate $\hat{p}$, the extimated proportion of people who will vote for Donald Trump in the population level, which is:

\begin{align}
\hat{p} & =\frac{e^{\hat{y}^{PS}}}{1+ e^{\hat{y}^{PS}}} \nonumber \\
& = \frac{0.9018719} {1+ 0.9018719} \nonumber \\
& = 0.4742022 
\end{align}

# Discussion

This report uses multilevel regression with post-stratification to predict the winner of the 2020 American federal election using non-representative data. Here, we focus on the two major candidates, Donald Trump and Joe Biden. We first build a logistic regression model to estimate the proportion of people who will vote for Donald Trump using survey data from Tausanovitch, Chris, and Lynn Vavreck (2020). We use age, gender, race, household income, and states to build the model. Then, we do a post-stratification to apply the model to the target population using the census data from IPUMS (Ruggles et al., 2020).

After applying the model to the census data, we get the post-stratification estimate, which is $-0.1032828$. Then, we calculated the estimated proportion of people who will vote for Donald Trump based on the post-stratification estimate. The estimated proportion is $0.4742022$, so we expect that 47.42% of the total population will vote for Donald Trump. Because our model only focuses on the two major candidates, it is expected that 52.58% of the total population will vote for Joe Biden. Thus, based on our logistic regression model and post-stratification analysis, Joe Biden is expected to win the 2020 American federal election.

## Weaknesses

Even though we have successfully run the model and made the prediction, our analysis has some limitations. One major problem is that the post-stratification analysis requires detailed census data that contains much demographic information. For example, it would be helpful to add more variables such as people's previous voting data or their political positions in our logistic regression model and post-stratification analysis. However, the census data we used does not contain such information. Thus, we cannot include these kinds of information in our model, which may reduce our prediction accuracy.

Another limitation is that we only focus on the two major candidates. In our model, we assume all people will vote, and they will choose one of the two major candidates to simplify the analysis. However, some people may refuse to vote in real life, and some people may prefer other candidates. Because we did not cover these situations in our model, the prediction may not fully represent the actual outcome. 

## Next Steps

Because the result of the 2020 American federal election will be announced on Nov. 3rd, 2020 (Macaya, Hayes & Wagner, 2020), future studies are required to compare the election's actual result with our predicted result. For example, if Donald Trump won the election, our model would fail to predict the actual outcome. Future studies could then use another census data containing more demographic information, such as people's political positions, to build a more detailed model and make more dispersed cells. Then they could re-run the process and compare the model result with the actual result to see whether the model would make the right prediction. 

On the other hand, if Joe Biden won the election, our model would successfully predict the election winner. Future studies could then compare the proportion of people who voted for Biden with the number we predicted and improve our model to make the two numbers as close as possible.

\newpage

# References

Arnholt, A. (2017, February 13). Miscellaneous Tips. Retrieved October 28, 2020, from https://alanarnholt.github.io/GeneralStatistics/rmarkdown/MiscRmarkdown.html

Federal Election Commission. (2017). Election Results for the U.S. President, the U.S. Senate and the U.S. House of Representatives. Washington, D.C.: Federal Election Commission.

Harmel, R., & Yeh, Y. Y. (2015). China's age cohorts: differences in political attitudes and behavior. Social Science Quarterly, 96(1), 214-234.

Lockerbie, B. (2013). Race and religion: Voting behavior and political attitudes. Social Science Quarterly, 94(4), 1145-1158.

Macaya, M., Hayes, M., & Wagner, M. (2020, October 26). US election 2020: Latest news on Biden, Trump and voting. Retrieved October 26, 2020, from https://edition.cnn.com/politics/live-news/us-election-news-10-26-2020/index.html

O'Brien, C. E. (2012, October 19). Create an R Function to Convert State Codes to Full State Name. https://favorableoutcomes.wordpress.com/2012/10/19/create-an-r-function-to-convert-state-codes-to-full-state-name/.

Patterson, S. C., & Caldeira, G. A. (1983). Getting out the vote: Participation in gubernatorial elections. The American Political Science Review, 675-689.

Pratto, F., Stallworth, L. M., & Sidanius, J. (1997). The gender gap: Differences in political attitudes and social dominance orientation. British journal of social psychology, 36(1), 49-68.

R Core Team (2019). R: A language and environment for statistical computing. R Foundation
for Statistical Computing, Vienna, Austria. URL https://www.R-project.org/.

Ruggles, S., Flood, S., Goeken, R., Grover, J., Meyer, E., Pacas, J., & Sobek, M. (2020). IPUMS USA: Version 10.0 [dataset]. Minneapolis, MN: IPUMS. https://doi.org/10.18128/D010.V10.0

Tausanovitch, Chris, & Vavreck, L. (2020). Democracy Fund + UCLA Nationscape, October 10-17, 2019 (version 20200814). Retrieved from https://www.voterstudygroup.org/downloads?key=a359a384-faaa-4117-b988-9357b6db90b0.

Wang, W., Rothschild, D., Goel, S., & Gelman, A. (2015). Forecasting elections with non-representative polls. International Journal of Forecasting, 31(3), 980-991.

Wickham et al., (2019). Welcome to the tidyverse. Journal of Open Source Software, 4(43),
1686, https://doi.org/10.21105/joss.01686

\newpage

# Appendix
\center Full Table of the Logistic Regression Model \center 

```{r, echo=FALSE}
print(model_summary, n=61)
```
